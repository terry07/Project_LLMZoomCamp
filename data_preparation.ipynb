{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fetch_data import read_docs_from_csv\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"./data_folder/documents.csv\"\n",
    "loaded_docs = read_docs_from_csv(csv_path, flatten_metadata=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'file_type': '.md', 'filename': 'how-to-build-a-u-net-for-image-segmentation-with-tensorflow-and-keras.md', 'chunk_index': 0, 'directory': 'main page', 'size': 13534, 'categories': 'deep-learning frameworks', 'chunk_size': 1880, 'total_chunks': 8, 'title': 'How to build a U-Net for image segmentation with TensorFlow and Keras', 'tags': 'classification computer-vision deep-learning image-segmentation keras machine-learning neural-network tensorflow unet'}, page_content=\"Computer vision has a few sub disciplines - and image segmentation is one of them. If you're segmenting an image, you're deciding about what is visible in the image at pixel level (when performing classification) - or inferring relevant real-valued information from the image at pixel level (when performing regression).\\n\\nOne of the prominent architectures in the image segmentation community is U-Net. Having been named after its shape, the fully-convolutional architecture first contracts an image followed by its expansion into the outcome. While this contracting path builds up a hierarchy of learned features, skip connections help transform these features back into a relevant model output in the expansive path.\\n\\nWhile you can learn more about the U-net architecture by clicking this link, this article focuses on a practical implementation. Today, you will learn to build a U-Net architecture from scratch. You will use TensorFlow and Keras for doing so. Firstly, you're going to briefly cover the components of a U-Net at a high level. This is followed by a step-by-step tutorial for implementing U-Net yourself. Finally, we're going to train the network on the Oxford-IIIT Pet Dataset from scratch, show you what can be achieved _and_ how to improve even further!\\n\\nSo, after reading this tutorial, you will understand...\\n\\n- What the U-Net architecture is and what its components are.\\n- How to build a U-Net yourself using TensorFlow and Keras.\\n- What performance you can achieve with your implementation and how to improve even further.\\n\\nAre you ready? Let's take a look! ðŸ˜Ž\\n\\n\\n\\n## What is a U-Net?\\n\\nWhen you ask a computer vision engineer about _image segmentation_, it's likely that the term U-Net will be mentioned somewhere in their explanation!\\n\\nThe U-Net, which is named after its shape, is a convolutional architecture originally proposed by Ronneberger et al. (2015) for use in the biomedical sciences. More specifically, it is used for cell segmentation, and worked really well compared to approaches previously used in the field.\\n\\nMachineCurve has an in-depth article explaining U-Net, and here we will review the components at a high-level only. U-Nets are composed of three component groups:\\n\\n1. A contracting path. Visible to the left in the image below, groups of convolutions and pooling layers are used to downsample the image, sometimes even halving it in size. The contracting path learns a hierarchy of features at varying levels of granularity.\\n2. An expansive path. To the right, you see groups of _upsampling layers_ (whether simple interpolation layers or transposed convolutions) that upsample the resolution of the input image. In other words, from the contracted input, the network tries to construct a higher-resolution output.\\n3. Skip connections. Besides having the lower-level feature maps as input to the upsampling process, U-Net also receives information from the contracting path's same-level layer. This is to mitigate the information bottleneck present at the lowest layer in the U, effectively 'dropping' the signal from higher-level features if not used through skip connections.\\n\\nNote that in the original U-Net architecture, the width and height of the output are lower than the input width and height (572x572 pixels versus 388x388 pixels). This originates in the architecture and can be avoided by using another default architecture (such as ResNet) as your backbone architecture. This will be covered in another article.\\n\\nWith architectures like U-Net, it becomes possible to learn features important to specific images, while using this information to generate a higher-resolution output. Maps representing class indexes at pixel level can be such output. And by reading further, you will learn to build a U-Net for doing so!\\n\\n\\n\\nInspired by Ronneberger et al. (2015)\\n\\n* * *\\n\\n## Building a U-Net with TensorFlow and Keras\\n\\nNow that you understand how U-Net works at a high level, it's time to build one. Open up your IDE and create a Python file (such as `unet.py`) or open up a Jupyter Notebook. Also ensure that you have installed the prerequisites, which follow next. We can then start writing some code!\\n\\n### Prerequisites\\n\\nFor running today's code, it's important that you have installed some dependencies into your environment.\\n\\nFirst of all, you will need a recent version of Python - 3.x, preferably 3.9+.\\n\\nIn addition, you will need `tensorflow` and `matplotlib`. These can be installed through `pip` package manager. When installed, you're ready to go!\\n\\n### Today's structure\\n\\nBuilding a U-Net model can be grouped into three separate groups, besides specifying model imports:\\n\\n1. Defining the configuration of your U-Net model, so that it can be reused throughout your code.\\n2. Defining the building blocks of your U-Net.\\n3. Defining the process definitions to train and evaluate your U-Net model.\\n\\nAfterwards, you will merge everything together into a working whole.\\n\\nLet's begin with model configuration! :)\\n\\n### Imports\\n\\nYour first lines of code will cover the imports that you will need in the rest of your code. Let's walk through them briefly:\\n\\n- Python `os` represents operating system functions such as constructing file paths. You will need it when loading your dataset.\\n- TensorFlow speaks pretty much for itself, doesn't it? :)\\n- A variety of layers will be used in your model. As we are working with Keras for building your neural network, they must be imported from `tensorflow.keras.layers`. You will use two-dimensional convolutional layers (`Conv2D`), two-dimensional max pooling (`MaxPool2D`), transposed convolutions (`Conv2DTranspose`), and more general layers, such as the `Input` layer (representing the input batch), `Activation` (representing a nonlinear activation function), `Concatenate` for Tensor concatenation and `CenterCrop` for taking a crop of the skip connections to match shapes (this will be discussed later).\\n- In addition, you will need to import the `Model` class for constructing your U-Net, He normal initialization via `HeNormal`, `Adam` for optimization including learning rate scheduling functionality (`schedules`), and sparse categorical crossentropy (`SparseCategoricalCrossentropy`) as your loss function.\\n- Recall that TensorFlow has a variety of callbacks that make your modelling life easier. An example of these callbacks is the TensorBoard callback, which allows you to have your training progress exported to a great tool for visualization. Finally, you will import a Keras `util` called `plot_model` for plotting the structure of your model.\\n- What rests are other imports. Our dataset is represented in `tensorflow_datasets` and finally you will also need Matplotlib's `pyplot` librari for visualization purposes.\\n\\n```python\\nimport os\\nimport tensorflow\\nfrom tensorflow.keras.layers import Conv2D,\\\\\\n\\tMaxPool2D, Conv2DTranspose, Input, Activation,\\\\\\n\\tConcatenate, CenterCrop\\nfrom tensorflow.keras import Model\\nfrom tensorflow.keras.initializers import HeNormal\\nfrom tensorflow.keras.optimizers import schedules, Adam\\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\\nfrom tensorflow.keras.callbacks import TensorBoard\\nfrom tensorflow.keras.utils import plot_model\\nimport tensorflow_datasets as tfds\\nimport matplotlib.pyplot as plt\\n```\\n\\n### U-Net configuration definition\\n\\nIn my view, it's bad practice to scatter a variety of configuration options throughout your model. Rather, I prefer to define them in one definition, allowing me to reuse them across the model (and should I ever need to deploy my model into a production setting, I can for example provide my configuration through a JSON environment variable which can be easily read into Python as a `dict`). Here's what the configuration definition looks like. Below, we'll discuss the components:\\n\\n```python\\n'''\\n\\tU-NET CONFIGURATION\\n'''\\ndef configuration():\\n\\t''' Get configuration. '''\\n\\n\\treturn dict(\\n\\t\\tdata_train_prc = 80,\\n\\t\\tdata_val_prc = 90,\\n\\t\\tdata_test_prc = 100,\\n\\t\\tnum_filters_start = 64,\\n\\t\\tnum_unet_blocks = 3,\\n\\t\\tnum_filters_end = 3,\\n\\t\\tinput_width = 100,\\n\\t\\tinput_height = 100,\\n\\t\\tmask_width = 60,\\n\\t\\tmask_height = 60,\\n\\t\\tinput_dim = 3,\\n\\t\\toptimizer = Adam,\\n\\t\\tloss = SparseCategoricalCrossentropy,\\n\\t\\tinitializer = HeNormal(),\\n\\t\\tbatch_size = 50,\\n\\t\\tbuffer_size = 50,\\n\\t\\tnum_epochs = 50,\\n\\t\\tmetrics = ['accuracy'],\\n\\t\\tdataset_path = os.path.join(os.getcwd(), 'data'),\\n\\t\\tclass_weights = tensorflow.constant([1.0, 1.0, 2.0]),\\n\\t\\tvalidation_sub_splits = 5,\\n\\t\\tlr_schedule_percentages = [0.2, 0.5, 0.8],\\n\\t\\tlr_schedule_values = [3e-4, 1e-4, 1e-5, 1e-6],\\n\\t\\tlr_schedule_class = schedules.PiecewiseConstantDecay\\n\\t)\\n```\"),\n",
       " Document(metadata={'file_type': '.md', 'filename': 'how-to-build-a-u-net-for-image-segmentation-with-tensorflow-and-keras.md', 'chunk_index': 1, 'directory': 'main page', 'size': 13534, 'categories': 'deep-learning frameworks', 'chunk_size': 1962, 'total_chunks': 8, 'title': 'How to build a U-Net for image segmentation with TensorFlow and Keras', 'tags': 'classification computer-vision deep-learning image-segmentation keras machine-learning neural-network tensorflow unet'}, page_content='- Recall that a dataset must be split into a training set, validation set and testing set. The training set is the largest and primary set, allowing you to make forward & backward passes and optimization during your training process. However, because you have seen this dataset, a validation set is used during training to evaluate performance after every epoch. Finally, because the model may eventually overfit on this validation set too, there is a testing set, which is not used during training at all. Rather, it is used during model evaluation to find whether your model performs on data that it has not seen before. If it does so, it\\'s more likely to work in the real world, too.\\n    - In your model configuration, `data_train_prc`, `data_val_prc` and `data_test_prc` are used to represent the percentage at which the specific split ends. In the configuration above, 80, 90 and 100 mean that 0-80% of your dataset will be used for training purposes, 80-90% (i.e. 10% in total) for validation and 90-100% (10%, too) for testing. You will see later that it\\'s good to specify them in this way, because `tfds.load` allows us to recombine the two datasets (train/test) and split them into three!\\n- The number of feature maps generated at the first U-net convolutional block will be 64. In total, your network will consist of 3 U-Net blocks (the sketch above has 5, but we found 3 to work better on this dataset) and will have 3 feature maps in the _final 1x1 Conv layer_. It\\'s set to 3 because our dataset has three possible classes to assign to each pixel - in other words, it should be equal to the number of classes in your dataset.\\n- The width and height of our input image will be 100 pixels. Dimensionality of the input will be 3 channels (it\\'s an RGB image).\\n- The width and height of the output mask will be 60 pixels. Indeed, in the original U-Net architecture input and output size is not equal to each other!\\n- Model wise, the Adam optimizer, sparse categorical crossentropy and He normal initialization are used. For the Adam optimizer, we use a learning rate schedule called `PiecewiseConstantDecay`. This schedule ensures that the learning rate is set to a preconfigured value after a predefined amount of training time. We start with a learning rate of `3e-4` (i.e., 0.0003) and decrease to `1e-4`, `1e-5` and `1e-6` after 20%, 50% and 80% of training. Decreasing your learning rate will help you move towards an optimum in a better way. Read here why.\\n- Training wise, we generate batches of 50 pixels and perform shuffling with a 50 buffer size, and train the model for 50 epochs.\\n- As an additional metric, we use `accuracy`.\\n- Our dataset will be located in the current working directory, `data` sub folder. 5 sub splits are used for validation purposes.\\n- When you are training with an imbalanced dataset, it can be a good idea to assign class weights to the target predictions. This will put more importance on the weights that are underrepresented.\\n\\nOkay, this was the important but relatively boring part. Let\\'s now build some U-Net blocks! :)\\n\\n### U-Net building blocks\\n\\nRecall that a U-Net is composed of a contracting path, which itself is built from convolutional blocks, and an expansive path built from upsampling blocks. At each individual level (except for the last level in the contractive path, which is connected to the head of the expansive path) the output of a convolutional block is connected to an upsampling block via a skip connection.\\n\\nYou will start with building a convolutional block and creating many of them in the contracting path. Then, you will do the same for the upsampling block and the expansive path.\\n\\n#### The convolutional block\\n\\nHere\\'s the structure of your `conv_block`:\\n\\n```python\\n\\'\\'\\'\\n\\tU-NET BUILDING BLOCKS\\n\\'\\'\\'\\n\\ndef conv_block(x, filters, last_block):\\n\\t\\'\\'\\'\\n\\t\\tU-Net convolutional block.\\n\\t\\tUsed for downsampling in the contracting path.\\n\\t\\'\\'\\'\\n\\tconfig = configuration()\\n\\n\\t# First Conv segment\\n\\tx = Conv2D(filters, (3, 3),\\\\\\n\\t\\tkernel_initializer=config.get(\"initializer\"))(x)\\n\\tx = Activation(\"relu\")(x)\\n\\n\\t# Second Conv segment\\n\\tx = Conv2D(filters, (3, 3),\\\\\\n\\t\\tkernel_initializer=config.get(\"initializer\"))(x)\\n\\tx = Activation(\"relu\")(x)\\n\\n\\t# Keep Conv output for skip input\\n\\tskip_input = x\\n\\n\\t# Apply pooling if not last block\\n\\tif not last_block:\\n\\t\\tx = MaxPool2D((2, 2), strides=(2,2))(x)\\n\\n\\treturn x, skip_input\\n```\\n\\nEach convolutional block, per the Ronneberger et al. (2015) paper, is composed of two 3x3 convolutional blocks the output of which are each ReLU activated. Per the configuration, He initialization is used (because we use ReLU activation).\\n\\n> It consists of the repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling.\\n>\\n> Ronneberger et al. (2015)\\n\\nRecall from the image above that at each level, the output of the convolutions in the convolutional block is passed as a skip connection to the first upsampling layer in the upsampling block at the corresponding level.\\n\\nMax pooling is applied to the same output, so that the output can be used by the next convolutional block.\\n\\n\\n\\nIn the code above, you can see that the output of the convolutional layers is assigned to `skip_input`. Subsequently, if this is not the last convolutional block, you will see that `MaxPool2D` is applied with a 2x2 pool size and stride 2.\\n\\nBoth the processed Tensor `x` and the skip connection `skip_input` are returned. Note that this also happens in the last layer! It\\'s only what whe do with the returned values that counts, and you will see that we don\\'t use the skip connection when it\\'s the last layer when creating the full contracting path.\\n\\n#### Contracting path and skip connections\\n\\nWhich, as if it is meant to be, is right now! :)\\n\\nLet\\'s create another definition called `contracting_path`. In it, you will construct the convolutional block that belong to the contracting path. Per your code above, these convolutional blocks will perform feature learning at their level of hierarchy and subsequently perform max pooling to make the Tensors ready for the next convolutional block.\\n\\nIn the original U-Net, at each \"downsampling step\" (i.e., max pooling, although a regular convolution is a downsampling step too, strictly speaking), the number of feature channels is doubled.\\n\\n> At each downsampling step we double the number of feature channels.\\n>\\n> Ronneberger et al. (2015)\\n\\nAnd you will need to take this into account when creating your contracting path. This is why you will use the utility function `compute_number_of_filters` (you will define it next) to compute the number of filters used within each convolutional block. Given the starting number of 64, that will be 64, 128 and 256 for the 3-block U-Net that you are building today (per your model configuration). For the original 5-block U-Net in Ronneberger et al. (2014), that would be 64, 128, 256, 512 and 1024.\\n\\nNext, you create a list where the Tensors provided by the convolutions can be stored. It serves as a container for the skip connections.\\n\\nNow, it\\'s time to create the actual blocks. By using `enumerate` you can create an enumerator that outputs `(index, value)`, and you are doing that to create a `for` loop that provides both the block number (`index`) and the number of filters in that particular block (`block_num_filters`). In the loop, you check if it\\'s the last block, and let the input pass through the convolutional block setting the number of filters given the level of your convolutional block.\\n\\nThen, if it\\'s not the last block, you\\'ll add the `skip_input` to the `skip_inputs` container.\\n\\nFinally, you return both `x` (which now has passed through the entire contracting path) and the `skip_inputs` skip connection Tensors produced when doing so.\\n\\n```python\\ndef contracting_path(x):\\n\\t\\'\\'\\'\\n\\t\\tU-Net contracting path.\\n\\t\\tInitializes multiple convolutional blocks for\\n\\t\\tdownsampling.\\n\\t\\'\\'\\'\\n\\tconfig = configuration()\\n\\n\\t# Compute the number of feature map filters per block\\n\\tnum_filters = [compute_number_of_filters(index)\\\\\\n\\t\\t\\tfor index in range(config.get(\"num_unet_blocks\"))]\\n\\n\\t# Create container for the skip input Tensors\\n\\tskip_inputs = []\\n\\n\\t# Pass input x through all convolutional blocks and\\n\\t# add skip input Tensor to skip_inputs if not last block\\n\\tfor index, block_num_filters in enumerate(num_filters):'),\n",
       " Document(metadata={'file_type': '.md', 'filename': 'how-to-build-a-u-net-for-image-segmentation-with-tensorflow-and-keras.md', 'chunk_index': 2, 'directory': 'main page', 'size': 13534, 'categories': 'deep-learning frameworks', 'chunk_size': 1955, 'total_chunks': 8, 'title': 'How to build a U-Net for image segmentation with TensorFlow and Keras', 'tags': 'classification computer-vision deep-learning image-segmentation keras machine-learning neural-network tensorflow unet'}, page_content='Then, if it\\'s not the last block, you\\'ll add the `skip_input` to the `skip_inputs` container.\\n\\nFinally, you return both `x` (which now has passed through the entire contracting path) and the `skip_inputs` skip connection Tensors produced when doing so.\\n\\n```python\\ndef contracting_path(x):\\n\\t\\'\\'\\'\\n\\t\\tU-Net contracting path.\\n\\t\\tInitializes multiple convolutional blocks for\\n\\t\\tdownsampling.\\n\\t\\'\\'\\'\\n\\tconfig = configuration()\\n\\n\\t# Compute the number of feature map filters per block\\n\\tnum_filters = [compute_number_of_filters(index)\\\\\\n\\t\\t\\tfor index in range(config.get(\"num_unet_blocks\"))]\\n\\n\\t# Create container for the skip input Tensors\\n\\tskip_inputs = []\\n\\n\\t# Pass input x through all convolutional blocks and\\n\\t# add skip input Tensor to skip_inputs if not last block\\n\\tfor index, block_num_filters in enumerate(num_filters):\\n\\n\\t\\tlast_block = index == len(num_filters)-1\\n\\t\\tx, skip_input = conv_block(x, block_num_filters,\\\\\\n\\t\\t\\tlast_block)\\n\\n\\t\\tif not last_block:\\n\\t\\t\\tskip_inputs.append(skip_input)\\n\\n\\treturn x, skip_inputs\\n```\\n\\n#### Utility function: computing number of feature maps\\n\\nIn the `contracting_path` definition, you were using `compute_number_of_filters` to compute the number of filters that must be used / feature maps that must be generated at a specific convolutional block.\\n\\nThis utility function is actually really simple: you take the number of filters in your first convolutional block (which, per your model configuration is 64) and multiply it with \\\\[latex\\\\]2^{\\\\\\\\text{level}}\\\\[/latex\\\\]. For example, at the third level (with index = 2) your convolutional block has \\\\[latex\\\\]64 \\\\\\\\times 2^2 = 256\\\\[/latex\\\\] filters.\\n\\n```python\\ndef compute_number_of_filters(block_number):\\n\\t\\'\\'\\'\\n\\t\\tCompute the number of filters for a specific\\n\\t\\tU-Net block given its position in the contracting path.\\n\\t\\'\\'\\'\\n\\treturn configuration().get(\"num_filters_start\") * (2 ** block_number)\\n```\\n\\n#### The upsampling block\\n\\nSo far, you have created code for downsampling your input data. It\\'s now time to shape the building blocks for the expansive path. Let\\'s add another definition, which you\\'ll call `upconv_block`. It takes some input, an expected number of filters, a skip input Tensor corresponding to the hierarchical level of your upsampling block, and information about whether it\\'s the last block.\\n\\n\\n\\nPer the design of U-Net, the first step is performing upsampling. In the image to the right, for example, a 52x52x512 Tensor is upsampled to a 104x104x512 Tensor.\\n\\nIn computer vision models, there are two primary ways of performing upsampling:\\n\\n- By means of interpolation. This is the classic approach and is used by Ronneberger et al. (2015). An interpolation function, such as bicubic interpolation, is used to compute the missing pixels. In TensorFlow and Keras, this functionality is covered by the Upsampling blocks.\\n- By means of learned upsampling with transposed convolutions. Another approach would be using transposed convolutions, which are convolutions that work the other way around. Instead of using learned kernels/filters to _down_sample a larger image, they _up_sample the image, but also by using learned kernels/filters! In TensorFlow, these are represented by meansa of `ConvXDTranspose`. You will be using this type of upsampling because it is (1) more common today and (2) makes the whole model use trainable parameters where possible.\\n\\nSo, the first processing that happens to your input Tensor `x` is upsampling by means of `Conv2DTranspose`.\\n\\nThen it\\'s time to discuss the following important detail - the crop that is applied to the skip connection.\\n\\nNote that the shape of the first two dimensions of the output of your convolutional block at arbitrary level _L_ is larger than the shape of these dimensions at the corresponding upsampling block. For example, in the example below you see that a skip connection of shape 136x136 pixels must be concatenated with a 104x104 pixel Tensor.\\n\\n> Every step in the expansive path consists of an upsampling of the feature map followed by a 2x2 convolution (â€œup-convolutionâ€) that halves the number of feature channels, a concatenation with the correspondingly cropped feature map from the contracting path, and two 3x3 convolutions, each followed by a ReLU.\\n>\\n> Ronneberger et al. (2015)\\n\\nThis is not possible. Ronneberger et al. (2015), in their original implementation of U-Net, mitigate this problem by taking a _center crop_ from the feature maps generated by the convolutional block. This center crop has the same width and height of the upsampled Tensor; in our case, that is 104x104 pixels. Now, both Tensors can be concatenated.\\n\\n\\n\\nTo make this crop, you use TensorFlow\\'s `CenterCrop` layer to take a center crop from the skip input using the target width and height as specified by the upsampled Tensor.\\n\\nThen, you use the `Concatenate` layer to concatenate the cropped skip input with the upsampled Tensor, after which you can proceed with processing the whole. This, per the Ronneberger et al. (2015) and the quote above, is performed using two 3x3 convolutions followed by ReLU activation each.\\n\\n> At the final layer a 1x1 convolution is used to map each 64- component feature vector to the desired number of classes.\\n>\\n> Ronneberger et al. (2015)\\n\\nFinally, at the last layer, you apply an 1x1 convolution (preserving the width and height dimensions) that outputs a Tensor with C for the third dimension. C, here, represents the desired number of classes - something we have in our model configuration as `num_filters_end`, and indeed, that is three classes for today\\'s dataset! :)\\n\\nHere\\'s the code for creating your upsampling block:\\n\\n```python\\ndef upconv_block(x, filters, skip_input, last_block = False):\\n\\t\\'\\'\\'\\n\\t\\tU-Net upsampling block.\\n\\t\\tUsed for upsampling in the expansive path.\\n\\t\\'\\'\\'\\n\\tconfig = configuration()\\n\\n\\t# Perform upsampling\\n\\tx = Conv2DTranspose(filters//2, (2, 2), strides=(2, 2),\\\\\\n\\t\\tkernel_initializer=config.get(\"initializer\"))(x)\\n\\tshp = x.shape\\n\\n\\t# Crop the skip input, keep the center\\n\\tcropped_skip_input = CenterCrop(height = x.shape[1],\\\\\\n\\t\\twidth = x.shape[2])(skip_input)\\n\\n\\t# Concatenate skip input with x\\n\\tconcat_input = Concatenate(axis=-1)([cropped_skip_input, x])\\n\\n\\t# First Conv segment\\n\\tx = Conv2D(filters//2, (3, 3),\\n\\t\\tkernel_initializer=config.get(\"initializer\"))(concat_input)\\n\\tx = Activation(\"relu\")(x)\\n\\n\\t# Second Conv segment\\n\\tx = Conv2D(filters//2, (3, 3),\\n\\t\\tkernel_initializer=config.get(\"initializer\"))(x)\\n\\tx = Activation(\"relu\")(x)\\n\\n\\t# Prepare output if last block\\n\\tif last_block:\\n\\t\\tx = Conv2D(config.get(\"num_filters_end\"), (1, 1),\\n\\t\\t\\tkernel_initializer=config.get(\"initializer\"))(x)\\n\\n\\treturn x\\n```\\n\\n#### Expansive path using skip connections\\n\\nAs with the contracting path, you will also need to compose the upsampling layers in your expansive path.\\n\\nSimilar to the contracting path, you will also compute the number of filters for the blocks in your expansive path. This time, however, you start counting at the end - i.e., at the number of blocks minus one, because you are working from a high number of filters to a low number of filters.\\n\\nThen, you iterate over the number of filters, compute whether it\\'s the last block and compute the _level_ to take the skip input from, and pass the Tensor through your upsampling block.\\n\\nNow, should you feed your Tensor to all the blocks if they were composed, they would make a complete pass through the contracting path and the expansive path. Time to stitch together your U-Net components!\\n\\n```python\\ndef expansive_path(x, skip_inputs):\\n\\t\\'\\'\\'\\n\\t\\tU-Net expansive path.\\n\\t\\tInitializes multiple upsampling blocks for upsampling.\\n\\t\\'\\'\\'\\n\\tnum_filters = [compute_number_of_filters(index)\\\\\\n\\t\\t\\tfor index in range(configuration()\\\\\\n\\t\\t\\t\\t.get(\"num_unet_blocks\")-1, 0, -1)]\\n\\n\\tskip_max_index = len(skip_inputs) - 1\\n\\n\\tfor index, block_num_filters in enumerate(num_filters):\\n\\t\\tskip_index = skip_max_index - index\\n\\t\\tlast_block = index == len(num_filters)-1\\n\\t\\tx = upconv_block(x, block_num_filters,\\\\\\n\\t\\t\\tskip_inputs[skip_index], last_block)\\n\\n\\treturn x\\n```\\n\\n#### U-Net builder\\n\\n...which is something that we can do with the `build_unet` definition that you will create now.\\n\\nIt is a relatively simple definition. It constructs the input shape by means of the configured height, width and dimensionality of your input data, and then passes this to an `Input` layer - which is TensorFlow\\'s way of representing input data.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_docs[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(csv_path)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>metadata_file_type</th>\n",
       "      <th>metadata_filename</th>\n",
       "      <th>metadata_chunk_index</th>\n",
       "      <th>metadata_directory</th>\n",
       "      <th>metadata_size</th>\n",
       "      <th>metadata_categories</th>\n",
       "      <th>metadata_chunk_size</th>\n",
       "      <th>metadata_total_chunks</th>\n",
       "      <th>metadata_title</th>\n",
       "      <th>metadata_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computer vision has a few sub disciplines - an...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1880</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Recall that a dataset must be split into a t...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1962</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Then, if it's not the last block, you'll add t...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1955</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>```python\\ndef expansive_path(x, skip_inputs):...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>3</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1910</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># Bring classes into range [0, 2]\\n\\tinput_mas...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>4</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1880</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td># Initialize model\\n\\tmodel = init_model(steps...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>5</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1931</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td># Init optimizer\\n\\toptimizer_init = config.ge...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>6</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1929</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[](https://www.machinecurve.com/wp-content/upl...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-u-net-for-image-segmentation-wi...</td>\n",
       "      <td>7</td>\n",
       "      <td>main page</td>\n",
       "      <td>13534</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>524</td>\n",
       "      <td>8</td>\n",
       "      <td>How to build a U-Net for image segmentation wi...</td>\n",
       "      <td>classification computer-vision deep-learning i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If you want to visualize how your Keras model ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>1959</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Next, we'll dive more deeply into questions ar...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>1821</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>### Model configuration &amp; loading CIFAR10 data...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>1707</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>### Model evaluation\\n\\nFinally, we add this e...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>3</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>1371</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>* * *\\n\\n## Starting the training process\\n\\nN...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>4</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>1977</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>## Viewing model performance in TensorBoard\\n\\...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-tensorboard-with-keras.md</td>\n",
       "      <td>5</td>\n",
       "      <td>main page</td>\n",
       "      <td>10561</td>\n",
       "      <td>buffer deep-learning frameworks</td>\n",
       "      <td>605</td>\n",
       "      <td>6</td>\n",
       "      <td>How to use TensorBoard with TensorFlow 2 and K...</td>\n",
       "      <td>deep-learning keras machine-learning neural-ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The inputs to individual layers in a neural ne...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-batch-normalization-with-keras.md</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>6179</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1945</td>\n",
       "      <td>3</td>\n",
       "      <td>How to use Batch Normalization with Keras?</td>\n",
       "      <td>batch-normalization deep-learning keras machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>This has to do with how Batch Normalization wo...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-batch-normalization-with-keras.md</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>6179</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1824</td>\n",
       "      <td>3</td>\n",
       "      <td>How to use Batch Normalization with Keras?</td>\n",
       "      <td>batch-normalization deep-learning keras machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>```python\\n# Reshape the training data to incl...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-use-batch-normalization-with-keras.md</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>6179</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1869</td>\n",
       "      <td>3</td>\n",
       "      <td>How to use Batch Normalization with Keras?</td>\n",
       "      <td>batch-normalization deep-learning keras machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Neural networks, and especially the deep ones,...</td>\n",
       "      <td>.md</td>\n",
       "      <td>visualizing-your-neural-network-with-netron.md</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>1975</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1661</td>\n",
       "      <td>1</td>\n",
       "      <td>Visualizing your Neural Network with Netron</td>\n",
       "      <td>architecture deep-learning deep-neural-network...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>After training a supervised machine learning m...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-create-a-confusion-matrix-with-scikit-l...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>4802</td>\n",
       "      <td>frameworks</td>\n",
       "      <td>1889</td>\n",
       "      <td>3</td>\n",
       "      <td>How to create a confusion matrix with Scikit-l...</td>\n",
       "      <td>confusion-matrix machine-learning model-evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The fraction of the train/test split determine...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-create-a-confusion-matrix-with-scikit-l...</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>4802</td>\n",
       "      <td>frameworks</td>\n",
       "      <td>1954</td>\n",
       "      <td>3</td>\n",
       "      <td>How to create a confusion matrix with Scikit-l...</td>\n",
       "      <td>confusion-matrix machine-learning model-evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td># Generate data\\ninputs, targets = make_blobs(...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-create-a-confusion-matrix-with-scikit-l...</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>4802</td>\n",
       "      <td>frameworks</td>\n",
       "      <td>537</td>\n",
       "      <td>3</td>\n",
       "      <td>How to create a confusion matrix with Scikit-l...</td>\n",
       "      <td>confusion-matrix machine-learning model-evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Transformer models like GPT-3 and BERT have be...</td>\n",
       "      <td>.md</td>\n",
       "      <td>albert-explained-a-lite-bert.md</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>5180</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>1972</td>\n",
       "      <td>3</td>\n",
       "      <td>ALBERT explained: A Lite BERT</td>\n",
       "      <td>albert bert deep-learning language-model machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>If things are not clear by now, don't worry - ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>albert-explained-a-lite-bert.md</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>5180</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>1859</td>\n",
       "      <td>3</td>\n",
       "      <td>ALBERT explained: A Lite BERT</td>\n",
       "      <td>albert bert deep-learning language-model machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The following results can be reported:\\n\\n- Th...</td>\n",
       "      <td>.md</td>\n",
       "      <td>albert-explained-a-lite-bert.md</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>5180</td>\n",
       "      <td>deep-learning</td>\n",
       "      <td>824</td>\n",
       "      <td>3</td>\n",
       "      <td>ALBERT explained: A Lite BERT</td>\n",
       "      <td>albert bert deep-learning language-model machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Convolutional neural networks are great tools ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-build-a-convnet-for-cifar-10-and-cifar-...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>9666</td>\n",
       "      <td>deep-learning frameworks</td>\n",
       "      <td>1953</td>\n",
       "      <td>5</td>\n",
       "      <td>How to build a ConvNet for CIFAR-10 and CIFAR-...</td>\n",
       "      <td>cifar10 cifar100 classifier cnn convolutional-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content metadata_file_type  \\\n",
       "0   Computer vision has a few sub disciplines - an...                .md   \n",
       "1   - Recall that a dataset must be split into a t...                .md   \n",
       "2   Then, if it's not the last block, you'll add t...                .md   \n",
       "3   ```python\\ndef expansive_path(x, skip_inputs):...                .md   \n",
       "4   # Bring classes into range [0, 2]\\n\\tinput_mas...                .md   \n",
       "5   # Initialize model\\n\\tmodel = init_model(steps...                .md   \n",
       "6   # Init optimizer\\n\\toptimizer_init = config.ge...                .md   \n",
       "7   [](https://www.machinecurve.com/wp-content/upl...                .md   \n",
       "8   If you want to visualize how your Keras model ...                .md   \n",
       "9   Next, we'll dive more deeply into questions ar...                .md   \n",
       "10  ### Model configuration & loading CIFAR10 data...                .md   \n",
       "11  ### Model evaluation\\n\\nFinally, we add this e...                .md   \n",
       "12  * * *\\n\\n## Starting the training process\\n\\nN...                .md   \n",
       "13  ## Viewing model performance in TensorBoard\\n\\...                .md   \n",
       "14  The inputs to individual layers in a neural ne...                .md   \n",
       "15  This has to do with how Batch Normalization wo...                .md   \n",
       "16  ```python\\n# Reshape the training data to incl...                .md   \n",
       "17  Neural networks, and especially the deep ones,...                .md   \n",
       "18  After training a supervised machine learning m...                .md   \n",
       "19  The fraction of the train/test split determine...                .md   \n",
       "20  # Generate data\\ninputs, targets = make_blobs(...                .md   \n",
       "21  Transformer models like GPT-3 and BERT have be...                .md   \n",
       "22  If things are not clear by now, don't worry - ...                .md   \n",
       "23  The following results can be reported:\\n\\n- Th...                .md   \n",
       "24  Convolutional neural networks are great tools ...                .md   \n",
       "\n",
       "                                    metadata_filename  metadata_chunk_index  \\\n",
       "0   how-to-build-a-u-net-for-image-segmentation-wi...                     0   \n",
       "1   how-to-build-a-u-net-for-image-segmentation-wi...                     1   \n",
       "2   how-to-build-a-u-net-for-image-segmentation-wi...                     2   \n",
       "3   how-to-build-a-u-net-for-image-segmentation-wi...                     3   \n",
       "4   how-to-build-a-u-net-for-image-segmentation-wi...                     4   \n",
       "5   how-to-build-a-u-net-for-image-segmentation-wi...                     5   \n",
       "6   how-to-build-a-u-net-for-image-segmentation-wi...                     6   \n",
       "7   how-to-build-a-u-net-for-image-segmentation-wi...                     7   \n",
       "8                how-to-use-tensorboard-with-keras.md                     0   \n",
       "9                how-to-use-tensorboard-with-keras.md                     1   \n",
       "10               how-to-use-tensorboard-with-keras.md                     2   \n",
       "11               how-to-use-tensorboard-with-keras.md                     3   \n",
       "12               how-to-use-tensorboard-with-keras.md                     4   \n",
       "13               how-to-use-tensorboard-with-keras.md                     5   \n",
       "14       how-to-use-batch-normalization-with-keras.md                     0   \n",
       "15       how-to-use-batch-normalization-with-keras.md                     1   \n",
       "16       how-to-use-batch-normalization-with-keras.md                     2   \n",
       "17     visualizing-your-neural-network-with-netron.md                     0   \n",
       "18  how-to-create-a-confusion-matrix-with-scikit-l...                     0   \n",
       "19  how-to-create-a-confusion-matrix-with-scikit-l...                     1   \n",
       "20  how-to-create-a-confusion-matrix-with-scikit-l...                     2   \n",
       "21                    albert-explained-a-lite-bert.md                     0   \n",
       "22                    albert-explained-a-lite-bert.md                     1   \n",
       "23                    albert-explained-a-lite-bert.md                     2   \n",
       "24  how-to-build-a-convnet-for-cifar-10-and-cifar-...                     0   \n",
       "\n",
       "   metadata_directory  metadata_size              metadata_categories  \\\n",
       "0           main page          13534         deep-learning frameworks   \n",
       "1           main page          13534         deep-learning frameworks   \n",
       "2           main page          13534         deep-learning frameworks   \n",
       "3           main page          13534         deep-learning frameworks   \n",
       "4           main page          13534         deep-learning frameworks   \n",
       "5           main page          13534         deep-learning frameworks   \n",
       "6           main page          13534         deep-learning frameworks   \n",
       "7           main page          13534         deep-learning frameworks   \n",
       "8           main page          10561  buffer deep-learning frameworks   \n",
       "9           main page          10561  buffer deep-learning frameworks   \n",
       "10          main page          10561  buffer deep-learning frameworks   \n",
       "11          main page          10561  buffer deep-learning frameworks   \n",
       "12          main page          10561  buffer deep-learning frameworks   \n",
       "13          main page          10561  buffer deep-learning frameworks   \n",
       "14          main page           6179         deep-learning frameworks   \n",
       "15          main page           6179         deep-learning frameworks   \n",
       "16          main page           6179         deep-learning frameworks   \n",
       "17          main page           1975         deep-learning frameworks   \n",
       "18          main page           4802                       frameworks   \n",
       "19          main page           4802                       frameworks   \n",
       "20          main page           4802                       frameworks   \n",
       "21          main page           5180                    deep-learning   \n",
       "22          main page           5180                    deep-learning   \n",
       "23          main page           5180                    deep-learning   \n",
       "24          main page           9666         deep-learning frameworks   \n",
       "\n",
       "    metadata_chunk_size  metadata_total_chunks  \\\n",
       "0                  1880                      8   \n",
       "1                  1962                      8   \n",
       "2                  1955                      8   \n",
       "3                  1910                      8   \n",
       "4                  1880                      8   \n",
       "5                  1931                      8   \n",
       "6                  1929                      8   \n",
       "7                   524                      8   \n",
       "8                  1959                      6   \n",
       "9                  1821                      6   \n",
       "10                 1707                      6   \n",
       "11                 1371                      6   \n",
       "12                 1977                      6   \n",
       "13                  605                      6   \n",
       "14                 1945                      3   \n",
       "15                 1824                      3   \n",
       "16                 1869                      3   \n",
       "17                 1661                      1   \n",
       "18                 1889                      3   \n",
       "19                 1954                      3   \n",
       "20                  537                      3   \n",
       "21                 1972                      3   \n",
       "22                 1859                      3   \n",
       "23                  824                      3   \n",
       "24                 1953                      5   \n",
       "\n",
       "                                       metadata_title  \\\n",
       "0   How to build a U-Net for image segmentation wi...   \n",
       "1   How to build a U-Net for image segmentation wi...   \n",
       "2   How to build a U-Net for image segmentation wi...   \n",
       "3   How to build a U-Net for image segmentation wi...   \n",
       "4   How to build a U-Net for image segmentation wi...   \n",
       "5   How to build a U-Net for image segmentation wi...   \n",
       "6   How to build a U-Net for image segmentation wi...   \n",
       "7   How to build a U-Net for image segmentation wi...   \n",
       "8   How to use TensorBoard with TensorFlow 2 and K...   \n",
       "9   How to use TensorBoard with TensorFlow 2 and K...   \n",
       "10  How to use TensorBoard with TensorFlow 2 and K...   \n",
       "11  How to use TensorBoard with TensorFlow 2 and K...   \n",
       "12  How to use TensorBoard with TensorFlow 2 and K...   \n",
       "13  How to use TensorBoard with TensorFlow 2 and K...   \n",
       "14         How to use Batch Normalization with Keras?   \n",
       "15         How to use Batch Normalization with Keras?   \n",
       "16         How to use Batch Normalization with Keras?   \n",
       "17        Visualizing your Neural Network with Netron   \n",
       "18  How to create a confusion matrix with Scikit-l...   \n",
       "19  How to create a confusion matrix with Scikit-l...   \n",
       "20  How to create a confusion matrix with Scikit-l...   \n",
       "21                      ALBERT explained: A Lite BERT   \n",
       "22                      ALBERT explained: A Lite BERT   \n",
       "23                      ALBERT explained: A Lite BERT   \n",
       "24  How to build a ConvNet for CIFAR-10 and CIFAR-...   \n",
       "\n",
       "                                        metadata_tags  \n",
       "0   classification computer-vision deep-learning i...  \n",
       "1   classification computer-vision deep-learning i...  \n",
       "2   classification computer-vision deep-learning i...  \n",
       "3   classification computer-vision deep-learning i...  \n",
       "4   classification computer-vision deep-learning i...  \n",
       "5   classification computer-vision deep-learning i...  \n",
       "6   classification computer-vision deep-learning i...  \n",
       "7   classification computer-vision deep-learning i...  \n",
       "8   deep-learning keras machine-learning neural-ne...  \n",
       "9   deep-learning keras machine-learning neural-ne...  \n",
       "10  deep-learning keras machine-learning neural-ne...  \n",
       "11  deep-learning keras machine-learning neural-ne...  \n",
       "12  deep-learning keras machine-learning neural-ne...  \n",
       "13  deep-learning keras machine-learning neural-ne...  \n",
       "14  batch-normalization deep-learning keras machin...  \n",
       "15  batch-normalization deep-learning keras machin...  \n",
       "16  batch-normalization deep-learning keras machin...  \n",
       "17  architecture deep-learning deep-neural-network...  \n",
       "18  confusion-matrix machine-learning model-evalua...  \n",
       "19  confusion-matrix machine-learning model-evalua...  \n",
       "20  confusion-matrix machine-learning model-evalua...  \n",
       "21  albert bert deep-learning language-model machi...  \n",
       "22  albert bert deep-learning language-model machi...  \n",
       "23  albert bert deep-learning language-model machi...  \n",
       "24  cifar10 cifar100 classifier cnn convolutional-...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      main page\n",
       "1      main page\n",
       "2      main page\n",
       "3      main page\n",
       "4      main page\n",
       "         ...    \n",
       "652    main page\n",
       "653    main page\n",
       "654    main page\n",
       "655    main page\n",
       "656    main page\n",
       "Name: metadata_directory, Length: 657, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['metadata_directory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                   0\n",
       "metadata_file_type        0\n",
       "metadata_filename         0\n",
       "metadata_chunk_index      0\n",
       "metadata_directory        0\n",
       "metadata_size             0\n",
       "metadata_categories      13\n",
       "metadata_chunk_size       0\n",
       "metadata_total_chunks     0\n",
       "metadata_title            0\n",
       "metadata_tags            13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>metadata_file_type</th>\n",
       "      <th>metadata_filename</th>\n",
       "      <th>metadata_chunk_index</th>\n",
       "      <th>metadata_directory</th>\n",
       "      <th>metadata_size</th>\n",
       "      <th>metadata_categories</th>\n",
       "      <th>metadata_chunk_size</th>\n",
       "      <th>metadata_total_chunks</th>\n",
       "      <th>metadata_title</th>\n",
       "      <th>metadata_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>We're being flooded with data related buzzword...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1961</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>#### Business\\n\\nData scientists must be able ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1957</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>However, while people working onÂ _general AI_ ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1917</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1. Making computers learn from data;\\n2. Witho...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>3</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1963</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>That's what makes deep learning so unique and ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>4</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1962</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>- By smartly combining multiple data sources i...</td>\n",
       "      <td>.md</td>\n",
       "      <td>the-differences-between-artificial-intelligenc...</td>\n",
       "      <td>5</td>\n",
       "      <td>main page</td>\n",
       "      <td>10415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129</td>\n",
       "      <td>6</td>\n",
       "      <td>The differences between AI, machine learning &amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Training a neural network with PyTorch also me...</td>\n",
       "      <td>.md</td>\n",
       "      <td>how-to-predict-new-samples-with-your-pytorch-m...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>2132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1885</td>\n",
       "      <td>1</td>\n",
       "      <td>How to predict new samples with your PyTorch m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Wav2vec 2Â is the successor of the Wav2vec mode...</td>\n",
       "      <td>.md</td>\n",
       "      <td>wav2vec-2-transformers-for-speech-recognition.md</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>Wav2vec 2: Transformers for Speech Recognition</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Since March 2020, the world is in crisis: the ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>ml-against-covid-19-detecting-disease-with-ten...</td>\n",
       "      <td>0</td>\n",
       "      <td>main page</td>\n",
       "      <td>10050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797</td>\n",
       "      <td>5</td>\n",
       "      <td>ML against COVID-19: detecting disease with Te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>```python\\nimport os\\nimport tensorflow\\nfrom ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>ml-against-covid-19-detecting-disease-with-ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>main page</td>\n",
       "      <td>10050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1949</td>\n",
       "      <td>5</td>\n",
       "      <td>ML against COVID-19: detecting disease with Te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>- Since we are dealing with categorical data, ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>ml-against-covid-19-detecting-disease-with-ten...</td>\n",
       "      <td>2</td>\n",
       "      <td>main page</td>\n",
       "      <td>10050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1937</td>\n",
       "      <td>5</td>\n",
       "      <td>ML against COVID-19: detecting disease with Te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td># Compile the ConvNet\\nmodel.compile(loss=tens...</td>\n",
       "      <td>.md</td>\n",
       "      <td>ml-against-covid-19-detecting-disease-with-ten...</td>\n",
       "      <td>3</td>\n",
       "      <td>main page</td>\n",
       "      <td>10050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1960</td>\n",
       "      <td>5</td>\n",
       "      <td>ML against COVID-19: detecting disease with Te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>```python\\nimport os\\nimport tensorflow\\nfrom ...</td>\n",
       "      <td>.md</td>\n",
       "      <td>ml-against-covid-19-detecting-disease-with-ten...</td>\n",
       "      <td>4</td>\n",
       "      <td>main page</td>\n",
       "      <td>10050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1512</td>\n",
       "      <td>5</td>\n",
       "      <td>ML against COVID-19: detecting disease with Te...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content metadata_file_type  \\\n",
       "93   We're being flooded with data related buzzword...                .md   \n",
       "94   #### Business\\n\\nData scientists must be able ...                .md   \n",
       "95   However, while people working onÂ _general AI_ ...                .md   \n",
       "96   1. Making computers learn from data;\\n2. Witho...                .md   \n",
       "97   That's what makes deep learning so unique and ...                .md   \n",
       "98   - By smartly combining multiple data sources i...                .md   \n",
       "275  Training a neural network with PyTorch also me...                .md   \n",
       "303  Wav2vec 2Â is the successor of the Wav2vec mode...                .md   \n",
       "462  Since March 2020, the world is in crisis: the ...                .md   \n",
       "463  ```python\\nimport os\\nimport tensorflow\\nfrom ...                .md   \n",
       "464  - Since we are dealing with categorical data, ...                .md   \n",
       "465  # Compile the ConvNet\\nmodel.compile(loss=tens...                .md   \n",
       "466  ```python\\nimport os\\nimport tensorflow\\nfrom ...                .md   \n",
       "\n",
       "                                     metadata_filename  metadata_chunk_index  \\\n",
       "93   the-differences-between-artificial-intelligenc...                     0   \n",
       "94   the-differences-between-artificial-intelligenc...                     1   \n",
       "95   the-differences-between-artificial-intelligenc...                     2   \n",
       "96   the-differences-between-artificial-intelligenc...                     3   \n",
       "97   the-differences-between-artificial-intelligenc...                     4   \n",
       "98   the-differences-between-artificial-intelligenc...                     5   \n",
       "275  how-to-predict-new-samples-with-your-pytorch-m...                     0   \n",
       "303   wav2vec-2-transformers-for-speech-recognition.md                     0   \n",
       "462  ml-against-covid-19-detecting-disease-with-ten...                     0   \n",
       "463  ml-against-covid-19-detecting-disease-with-ten...                     1   \n",
       "464  ml-against-covid-19-detecting-disease-with-ten...                     2   \n",
       "465  ml-against-covid-19-detecting-disease-with-ten...                     3   \n",
       "466  ml-against-covid-19-detecting-disease-with-ten...                     4   \n",
       "\n",
       "    metadata_directory  metadata_size metadata_categories  \\\n",
       "93           main page          10415                 NaN   \n",
       "94           main page          10415                 NaN   \n",
       "95           main page          10415                 NaN   \n",
       "96           main page          10415                 NaN   \n",
       "97           main page          10415                 NaN   \n",
       "98           main page          10415                 NaN   \n",
       "275          main page           2132                 NaN   \n",
       "303          main page            133                 NaN   \n",
       "462          main page          10050                 NaN   \n",
       "463          main page          10050                 NaN   \n",
       "464          main page          10050                 NaN   \n",
       "465          main page          10050                 NaN   \n",
       "466          main page          10050                 NaN   \n",
       "\n",
       "     metadata_chunk_size  metadata_total_chunks  \\\n",
       "93                  1961                      6   \n",
       "94                  1957                      6   \n",
       "95                  1917                      6   \n",
       "96                  1963                      6   \n",
       "97                  1962                      6   \n",
       "98                  1129                      6   \n",
       "275                 1885                      1   \n",
       "303                   50                      1   \n",
       "462                 1797                      5   \n",
       "463                 1949                      5   \n",
       "464                 1937                      5   \n",
       "465                 1960                      5   \n",
       "466                 1512                      5   \n",
       "\n",
       "                                        metadata_title metadata_tags  \n",
       "93   The differences between AI, machine learning &...           NaN  \n",
       "94   The differences between AI, machine learning &...           NaN  \n",
       "95   The differences between AI, machine learning &...           NaN  \n",
       "96   The differences between AI, machine learning &...           NaN  \n",
       "97   The differences between AI, machine learning &...           NaN  \n",
       "98   The differences between AI, machine learning &...           NaN  \n",
       "275  How to predict new samples with your PyTorch m...           NaN  \n",
       "303     Wav2vec 2: Transformers for Speech Recognition           NaN  \n",
       "462  ML against COVID-19: detecting disease with Te...           NaN  \n",
       "463  ML against COVID-19: detecting disease with Te...           NaN  \n",
       "464  ML against COVID-19: detecting disease with Te...           NaN  \n",
       "465  ML against COVID-19: detecting disease with Te...           NaN  \n",
       "466  ML against COVID-19: detecting disease with Te...           NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data [ data.metadata_tags.isnull() ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
