{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate parts of code for exploring them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken, requests \n",
    "from tqdm.auto import tqdm\n",
    "from markdownify import markdownify as md\n",
    "import os\n",
    "\n",
    "# load environment variables\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, are a type of machine learning model that are designed to quickly process and generate human-like language, while using significantly less computational resources and memory compared to traditional language models. The importance of fast language models lies in their ability to:\n",
      "\n",
      "1. **Enable real-time conversational AI**: Fast language models can be used to build conversational AI systems that can respond to user inputs in real-time, making them suitable for applications such as chatbots, voice assistants, and customer service platforms.\n",
      "2. **Improve latency**: Traditional language models can be slow to respond, which can lead to frustrating user experiences. Fast language models reduce latency, ensuring that users receive quick and accurate responses.\n",
      "3. **Enhance accessibility**: By requiring less powerful hardware and energy, fast language models can be deployed on resource-constrained devices, making them accessible to a broader range of users, including those with less powerful devices or limited internet connectivity.\n",
      "4. **Facilitate edge AI applications**: Fast language models can be trained and deployed on edge devices, such as smartphones, smart home devices, and IoT devices, enabling offline language processing and generating more localized and personalized experiences.\n",
      "5. **Accelerate language understanding**: Fast language models can process and understand natural language quickly, enabling applications such as language translation, sentiment analysis, and chatbots to respond more accurately and efficiently.\n",
      "6. **Reduce data requirements**: Fast language models can be trained on smaller datasets, reducing the need for large amounts of data and enabling training on smaller, more specific datasets.\n",
      "7. **Improve search and retrieval**: Fast language models can quickly retrieve and rank relevant documents, enabling more efficient search and retrieval applications.\n",
      "8. **Enhance product recommendations**: By analyzing customer reviews and feedback quickly, fast language models can provide more accurate and personalized product recommendations.\n",
      "9. **Support multilingual applications**: Fast language models can be trained on multiple languages, enabling applications such as translation, localization, and multilingual chatbots.\n",
      "10. **Pave the way for explainable AI**: Fast language models can help develop explainable AI systems, which are essential for building trust and understanding in AI-powered applications.\n",
      "\n",
      "The rapid development of fast language models is driven by the need for more efficient and scalable language processing capabilities, particularly in applications that require real-time interaction, such as conversational AI, voice assistants, and edge AI. As a result, researchers and developers are actively exploring techniques to improve the efficiency, accuracy, and scalability of fast language models.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or lightweight language models, are a type of machine learning model that are designed to quickly process and generate human\\-like language, while using significantly less computational resources and memory compared to traditional language models. The importance of fast language models lies in their ability to:\n",
      "\n",
      "1\\. \\*\\*Enable real\\-time conversational AI\\*\\*: Fast language models can be used to build conversational AI systems that can respond to user inputs in real\\-time, making them suitable for applications such as chatbots, voice assistants, and customer service platforms.\n",
      "2\\. \\*\\*Improve latency\\*\\*: Traditional language models can be slow to respond, which can lead to frustrating user experiences. Fast language models reduce latency, ensuring that users receive quick and accurate responses.\n",
      "3\\. \\*\\*Enhance accessibility\\*\\*: By requiring less powerful hardware and energy, fast language models can be deployed on resource\\-constrained devices, making them accessible to a broader range of users, including those with less powerful devices or limited internet connectivity.\n",
      "4\\. \\*\\*Facilitate edge AI applications\\*\\*: Fast language models can be trained and deployed on edge devices, such as smartphones, smart home devices, and IoT devices, enabling offline language processing and generating more localized and personalized experiences.\n",
      "5\\. \\*\\*Accelerate language understanding\\*\\*: Fast language models can process and understand natural language quickly, enabling applications such as language translation, sentiment analysis, and chatbots to respond more accurately and efficiently.\n",
      "6\\. \\*\\*Reduce data requirements\\*\\*: Fast language models can be trained on smaller datasets, reducing the need for large amounts of data and enabling training on smaller, more specific datasets.\n",
      "7\\. \\*\\*Improve search and retrieval\\*\\*: Fast language models can quickly retrieve and rank relevant documents, enabling more efficient search and retrieval applications.\n",
      "8\\. \\*\\*Enhance product recommendations\\*\\*: By analyzing customer reviews and feedback quickly, fast language models can provide more accurate and personalized product recommendations.\n",
      "9\\. \\*\\*Support multilingual applications\\*\\*: Fast language models can be trained on multiple languages, enabling applications such as translation, localization, and multilingual chatbots.\n",
      "10\\. \\*\\*Pave the way for explainable AI\\*\\*: Fast language models can help develop explainable AI systems, which are essential for building trust and understanding in AI\\-powered applications.\n",
      "\n",
      "The rapid development of fast language models is driven by the need for more efficient and scalable language processing capabilities, particularly in applications that require real\\-time interaction, such as conversational AI, voice assistants, and edge AI. As a result, researchers and developers are actively exploring techniques to improve the efficiency, accuracy, and scalability of fast language models.\n"
     ]
    }
   ],
   "source": [
    "print(md(chat_completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from elasticsearch import Elasticsearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
